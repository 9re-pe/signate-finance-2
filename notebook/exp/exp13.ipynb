{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "\n",
    "- Focal lossのチューニング"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_dir = \"../../\"\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "from modules import config as cfg\n",
    "from modules import utils, preprosess, training, predict, metrics\n",
    "\n",
    "exp = \"exp13\"\n",
    "utils.set_seed(cfg.Params.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:44:09.099988Z",
     "start_time": "2024-01-27T05:44:09.041283Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T07:23:00.806250Z",
     "start_time": "2024-01-21T07:22:58.502427Z"
    }
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:44:10.884444Z",
     "start_time": "2024-01-27T05:44:10.718493Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test, submit = utils.get_data(debug_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train = preprosess.assign_stratified_k_fold(train, \"MIS_Status\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:44:13.089952Z",
     "start_time": "2024-01-27T05:44:13.053827Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:44:15.181822Z",
     "start_time": "2024-01-27T05:44:14.898596Z"
    }
   },
   "outputs": [],
   "source": [
    "# 地名を座標に変換\n",
    "train = preprosess.convert_to_latlon(train)\n",
    "test  = preprosess.convert_to_latlon(test)\n",
    "\n",
    "# testのBankStateの\"PR\"はtrainにないため，一番多いCAに変換\n",
    "test = test.with_columns(pl.col(\"BankState\").str.replace(\"PR\", \"CA\"))\n",
    "\n",
    "# DisbursementDateとApprovalDateをYear(数値)に変換\n",
    "cols  = [\"DisbursementDate\", \"ApprovalDate\"]\n",
    "train = preprosess.convert_date_to_year(train, cols)\n",
    "test  = preprosess.convert_date_to_year(test, cols)\n",
    "\n",
    "# 金額データの数値化\n",
    "cols  = [\"DisbursementGross\",  \"GrAppv\", \"SBA_Appv\"]\n",
    "train = preprosess.convert_money_data(train, cols)\n",
    "test  = preprosess.convert_money_data(test, cols)\n",
    "\n",
    "# 一致しているか\n",
    "eqs = [\n",
    "    [\"State\", \"BankState\"],\n",
    "]\n",
    "train = preprosess.add_eq(train, eqs)\n",
    "test  = preprosess.add_eq(test, eqs)\n",
    "\n",
    "# 差の計算\n",
    "diffs = [\n",
    "    [\"DisbursementGross\", \"GrAppv\"],   # 支払われた額 vs 銀行承認額\n",
    "    [\"DisbursementGross\", \"SBA_Appv\"], # 支払われた額 vs SBA承認額\n",
    "    [\"GrAppv\", \"SBA_Appv\"],            # 銀行承認額 vs SBA承認額\n",
    "]\n",
    "train = preprosess.add_diff(train, diffs)\n",
    "test  = preprosess.add_diff(test, diffs)\n",
    "\n",
    "# DisbursementDateとApprovalDateの差を計算\n",
    "train = preprosess.add_diff_disbursement_with_approval(train)\n",
    "test  = preprosess.add_diff_disbursement_with_approval(test)\n",
    "\n",
    "# 割合の計算\n",
    "divs = [\n",
    "    # [\"DisbursementGross\", \"Term\"],\n",
    "    [\"GrAppv\", \"Term\"],\n",
    "    [\"SBA_Appv\", \"Term\"],\n",
    "    [\"NoEmp\", \"Term\"],\n",
    "    # [\"DisbursementGross\", \"NoEmp\"],\n",
    "    # [\"GrAppv\", \"NoEmp\"],\n",
    "    # [\"SBA_Appv\", \"NoEmp\"],\n",
    "    [\"DisbursementGross_GrAppv_diff\", \"Term\"],\n",
    "    [\"DisbursementGross_SBA_Appv_diff\", \"Term\"],\n",
    "    [\"GrAppv_SBA_Appv_diff\", \"Term\"],\n",
    "    # [\"DisbursementGross_GrAppv_diff\", \"NoEmp\"],\n",
    "    # [\"DisbursementGross_SBA_Appv_diff\", \"NoEmp\"],\n",
    "    # [\"GrAppv_SBA_Appv_diff\", \"NoEmp\"]\n",
    "]\n",
    "train = preprosess.add_div(train, divs)\n",
    "test  = preprosess.add_div(test, divs)\n",
    "\n",
    "# Sectorを職業別にする\n",
    "train = preprosess.unify_same_sector(train)\n",
    "test  = preprosess.unify_same_sector(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Target encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cols = [\n",
    "    # \"Sector\",\n",
    "    \"UrbanRural\",\n",
    "    \"RevLineCr\",\n",
    "    \"LowDoc\",\n",
    "    \"FranchiseCode\",\n",
    "]\n",
    "target_col = \"MIS_Status\"\n",
    "train, test = preprosess.target_encoding(train, test, cols)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:44:16.956741Z",
     "start_time": "2024-01-27T05:44:16.864526Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label encoding\n",
    "CVによるtarget encodingでは同じカテゴリカル変数に異なる値が割り当てられるのでlabel encodingを併用する"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cols = [\"RevLineCr\", \"LowDoc\"]\n",
    "train, test = preprosess.label_encoding(train, test, cols)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:44:18.632274Z",
     "start_time": "2024-01-27T05:44:18.571771Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Drop columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 不要なカラムの削除\n",
    "del_cols = [\n",
    "    # 地名系\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"BankState\",\n",
    "    # d-b-y系\n",
    "    \"DisbursementDate\",\n",
    "    \"ApprovalDate\",\n",
    "    \"ApprovalFY\",\n",
    "    # ラベルエンコーディング済み\n",
    "    \"RevLineCr\",\n",
    "    \"LowDoc\",\n",
    "]\n",
    "train = train.drop(del_cols)\n",
    "test  = test.drop(del_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:44:20.832260Z",
     "start_time": "2024-01-27T05:44:20.813263Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training + Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.1_gamma1.0: 0.365233\tvalid_1's Focal_alpha0.1_gamma1.0: 0.868078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[34]\ttraining's Focal_alpha0.1_gamma1.0: 0.0435572\tvalid_1's Focal_alpha0.1_gamma1.0: 0.24732\n",
      "Time:  4.573[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma1.0: 0.124496\tvalid_1's Focal_alpha0.1_gamma1.0: 0.544385\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\ttraining's Focal_alpha0.1_gamma1.0: 0.0452701\tvalid_1's Focal_alpha0.1_gamma1.0: 0.282723\n",
      "Time:  6.215[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma1.0: 0.677838\tvalid_1's Focal_alpha0.1_gamma1.0: 0.976768\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[47]\ttraining's Focal_alpha0.1_gamma1.0: 0.0411276\tvalid_1's Focal_alpha0.1_gamma1.0: 0.282421\n",
      "Time:  6.647[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma1.0: 0.15015\tvalid_1's Focal_alpha0.1_gamma1.0: 0.556577\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[49]\ttraining's Focal_alpha0.1_gamma1.0: 0.0441246\tvalid_1's Focal_alpha0.1_gamma1.0: 0.316813\n",
      "Time:  4.713[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma1.0: 0.0523166\tvalid_1's Focal_alpha0.1_gamma1.0: 0.56814\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[33]\ttraining's Focal_alpha0.1_gamma1.0: 0.045606\tvalid_1's Focal_alpha0.1_gamma1.0: 0.268179\n",
      "Time:  4.059[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.1_gamma2.0: 1.35746\tvalid_1's Focal_alpha0.1_gamma2.0: 1.59825\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[19]\ttraining's Focal_alpha0.1_gamma2.0: 0.0285623\tvalid_1's Focal_alpha0.1_gamma2.0: 0.146119\n",
      "Time:  3.575[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma2.0: 1.61259\tvalid_1's Focal_alpha0.1_gamma2.0: 1.71974\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[7]\ttraining's Focal_alpha0.1_gamma2.0: 0.0297933\tvalid_1's Focal_alpha0.1_gamma2.0: 0.0733323\n",
      "Time:  4.864[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma2.0: 1.73374\tvalid_1's Focal_alpha0.1_gamma2.0: 1.71005\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttraining's Focal_alpha0.1_gamma2.0: 0.0284184\tvalid_1's Focal_alpha0.1_gamma2.0: 0.0881259\n",
      "Time:  3.973[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma2.0: 1.11203\tvalid_1's Focal_alpha0.1_gamma2.0: 1.29257\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[17]\ttraining's Focal_alpha0.1_gamma2.0: 0.0281608\tvalid_1's Focal_alpha0.1_gamma2.0: 0.129549\n",
      "Time:  4.023[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma2.0: 1.88419\tvalid_1's Focal_alpha0.1_gamma2.0: 2.17066\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\ttraining's Focal_alpha0.1_gamma2.0: 0.0287995\tvalid_1's Focal_alpha0.1_gamma2.0: 0.234234\n",
      "Time:  5.544[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.1_gamma3.0: 2.83657\tvalid_1's Focal_alpha0.1_gamma3.0: 3.08951\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.1_gamma3.0: 0.0171413\tvalid_1's Focal_alpha0.1_gamma3.0: 0.0454065\n",
      "Time:  4.175[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma3.0: 2.93543\tvalid_1's Focal_alpha0.1_gamma3.0: 3.35406\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma3.0: 0.0171044\tvalid_1's Focal_alpha0.1_gamma3.0: 0.0243289\n",
      "Time:  5.787[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma3.0: 2.77952\tvalid_1's Focal_alpha0.1_gamma3.0: 2.98394\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.1_gamma3.0: 0.0169739\tvalid_1's Focal_alpha0.1_gamma3.0: 0.0356143\n",
      "Time:  4.309[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma3.0: 3.14982\tvalid_1's Focal_alpha0.1_gamma3.0: 3.38415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.1_gamma3.0: 0.0172113\tvalid_1's Focal_alpha0.1_gamma3.0: 0.033744\n",
      "Time:  5.141[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma3.0: 3.57171\tvalid_1's Focal_alpha0.1_gamma3.0: 3.93415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.1_gamma3.0: 0.0171135\tvalid_1's Focal_alpha0.1_gamma3.0: 0.0518563\n",
      "Time:  3.829[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.1_gamma4.0: 4.31117\tvalid_1's Focal_alpha0.1_gamma4.0: 4.30977\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma4.0: 0.00982312\tvalid_1's Focal_alpha0.1_gamma4.0: 0.0319442\n",
      "Time:  3.918[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma4.0: 3.91932\tvalid_1's Focal_alpha0.1_gamma4.0: 4.27515\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma4.0: 0.00949822\tvalid_1's Focal_alpha0.1_gamma4.0: 0.0164827\n",
      "Time:  3.662[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma4.0: 3.35624\tvalid_1's Focal_alpha0.1_gamma4.0: 3.37873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma4.0: 0.00961525\tvalid_1's Focal_alpha0.1_gamma4.0: 0.0227338\n",
      "Time:  3.728[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma4.0: 3.74815\tvalid_1's Focal_alpha0.1_gamma4.0: 3.5913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma4.0: 0.00965774\tvalid_1's Focal_alpha0.1_gamma4.0: 0.0197502\n",
      "Time:  3.904[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.1_gamma4.0: 3.51565\tvalid_1's Focal_alpha0.1_gamma4.0: 3.54252\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma4.0: 0.00976871\tvalid_1's Focal_alpha0.1_gamma4.0: 0.0386676\n",
      "Time:  4.441[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.1_gamma5.0: 3.65129\tvalid_1's Focal_alpha0.1_gamma5.0: 3.77177\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma5.0: 0.00599219\tvalid_1's Focal_alpha0.1_gamma5.0: 0.0276513\n",
      "Time:  3.439[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's Focal_alpha0.1_gamma5.0: 3.50647\tvalid_1's Focal_alpha0.1_gamma5.0: 3.66593\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma5.0: 0.0056886\tvalid_1's Focal_alpha0.1_gamma5.0: 0.0121458\n",
      "Time:  4.052[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.1_gamma5.0: 3.36056\tvalid_1's Focal_alpha0.1_gamma5.0: 3.37814\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma5.0: 0.0058072\tvalid_1's Focal_alpha0.1_gamma5.0: 0.018493\n",
      "Time:  4.352[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.1_gamma5.0: 3.76843\tvalid_1's Focal_alpha0.1_gamma5.0: 3.90205\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma5.0: 0.00585434\tvalid_1's Focal_alpha0.1_gamma5.0: 0.0155839\n",
      "Time:  3.533[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.1_gamma5.0: 3.48486\tvalid_1's Focal_alpha0.1_gamma5.0: 3.49767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.1_gamma5.0: 0.00593616\tvalid_1's Focal_alpha0.1_gamma5.0: 0.0341938\n",
      "Time:  3.831[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.2_gamma1.0: 1.5084\tvalid_1's Focal_alpha0.2_gamma1.0: 1.84502\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[32]\ttraining's Focal_alpha0.2_gamma1.0: 0.0656854\tvalid_1's Focal_alpha0.2_gamma1.0: 0.359874\n",
      "Time:  3.776[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma1.0: 0.650327\tvalid_1's Focal_alpha0.2_gamma1.0: 1.0813\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[32]\ttraining's Focal_alpha0.2_gamma1.0: 0.069424\tvalid_1's Focal_alpha0.2_gamma1.0: 0.307543\n",
      "Time:  3.357[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma1.0: 0.0882473\tvalid_1's Focal_alpha0.2_gamma1.0: 0.701608\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[57]\ttraining's Focal_alpha0.2_gamma1.0: 0.061788\tvalid_1's Focal_alpha0.2_gamma1.0: 0.518227\n",
      "Time:  4.190[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma1.0: 2.18032\tvalid_1's Focal_alpha0.2_gamma1.0: 3.17655\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[61]\ttraining's Focal_alpha0.2_gamma1.0: 0.0583467\tvalid_1's Focal_alpha0.2_gamma1.0: 0.424697\n",
      "Time:  3.663[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma1.0: 0.355357\tvalid_1's Focal_alpha0.2_gamma1.0: 1.10853\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[62]\ttraining's Focal_alpha0.2_gamma1.0: 0.0607349\tvalid_1's Focal_alpha0.2_gamma1.0: 0.635863\n",
      "Time:  3.624[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 1.60143\tvalid_1's Focal_alpha0.2_gamma2.0: 1.73868\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6]\ttraining's Focal_alpha0.2_gamma2.0: 0.0448094\tvalid_1's Focal_alpha0.2_gamma2.0: 0.139674\n",
      "Time:  4.284[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 1.83143\tvalid_1's Focal_alpha0.2_gamma2.0: 1.7892\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[22]\ttraining's Focal_alpha0.2_gamma2.0: 0.0457543\tvalid_1's Focal_alpha0.2_gamma2.0: 0.185867\n",
      "Time:  3.559[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 1.10057\tvalid_1's Focal_alpha0.2_gamma2.0: 1.30991\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[22]\ttraining's Focal_alpha0.2_gamma2.0: 0.0443517\tvalid_1's Focal_alpha0.2_gamma2.0: 0.241077\n",
      "Time:  3.886[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 3.03725\tvalid_1's Focal_alpha0.2_gamma2.0: 2.58239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4]\ttraining's Focal_alpha0.2_gamma2.0: 0.0445657\tvalid_1's Focal_alpha0.2_gamma2.0: 0.0983678\n",
      "Time:  5.347[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 2.56407\tvalid_1's Focal_alpha0.2_gamma2.0: 2.63903\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5]\ttraining's Focal_alpha0.2_gamma2.0: 0.0447159\tvalid_1's Focal_alpha0.2_gamma2.0: 0.141217\n",
      "Time:  4.312[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.2_gamma3.0: 4.53118\tvalid_1's Focal_alpha0.2_gamma3.0: 4.45927\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3]\ttraining's Focal_alpha0.2_gamma3.0: 0.0257884\tvalid_1's Focal_alpha0.2_gamma3.0: 0.0895795\n",
      "Time:  4.532[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma3.0: 4.36435\tvalid_1's Focal_alpha0.2_gamma3.0: 4.56558\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.2_gamma3.0: 0.0264206\tvalid_1's Focal_alpha0.2_gamma3.0: 0.0412545\n",
      "Time:  3.879[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma3.0: 3.96008\tvalid_1's Focal_alpha0.2_gamma3.0: 4.24584\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3]\ttraining's Focal_alpha0.2_gamma3.0: 0.0255513\tvalid_1's Focal_alpha0.2_gamma3.0: 0.0733346\n",
      "Time:  3.820[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma3.0: 4.10807\tvalid_1's Focal_alpha0.2_gamma3.0: 4.67513\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.2_gamma3.0: 0.0256543\tvalid_1's Focal_alpha0.2_gamma3.0: 0.0579258\n",
      "Time:  4.395[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma3.0: 3.74638\tvalid_1's Focal_alpha0.2_gamma3.0: 3.70335\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.2_gamma3.0: 0.025949\tvalid_1's Focal_alpha0.2_gamma3.0: 0.0891756\n",
      "Time:  3.786[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.2_gamma4.0: 4.72522\tvalid_1's Focal_alpha0.2_gamma4.0: 4.65597\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.2_gamma4.0: 0.0160136\tvalid_1's Focal_alpha0.2_gamma4.0: 0.0685556\n",
      "Time:  4.429[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma4.0: 4.8755\tvalid_1's Focal_alpha0.2_gamma4.0: 4.98592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.2_gamma4.0: 0.0160163\tvalid_1's Focal_alpha0.2_gamma4.0: 0.0305166\n",
      "Time:  4.521[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma4.0: 5.37859\tvalid_1's Focal_alpha0.2_gamma4.0: 5.66147\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.2_gamma4.0: 0.0163772\tvalid_1's Focal_alpha0.2_gamma4.0: 0.0444506\n",
      "Time:  3.610[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma4.0: 5.01528\tvalid_1's Focal_alpha0.2_gamma4.0: 5.04061\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.2_gamma4.0: 0.016316\tvalid_1's Focal_alpha0.2_gamma4.0: 0.0463411\n",
      "Time:  4.661[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma4.0: 5.10484\tvalid_1's Focal_alpha0.2_gamma4.0: 5.25299\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.2_gamma4.0: 0.0161963\tvalid_1's Focal_alpha0.2_gamma4.0: 0.0835455\n",
      "Time:  3.836[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's Focal_alpha0.2_gamma5.0: 3.85934\tvalid_1's Focal_alpha0.2_gamma5.0: 3.83887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.2_gamma5.0: 0.0111981\tvalid_1's Focal_alpha0.2_gamma5.0: 0.055538\n",
      "Time:  3.859[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.2_gamma5.0: 4.96327\tvalid_1's Focal_alpha0.2_gamma5.0: 4.81572\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.2_gamma5.0: 0.0105914\tvalid_1's Focal_alpha0.2_gamma5.0: 0.0240691\n",
      "Time:  5.478[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.2_gamma5.0: 4.47739\tvalid_1's Focal_alpha0.2_gamma5.0: 4.6736\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.2_gamma5.0: 0.0109562\tvalid_1's Focal_alpha0.2_gamma5.0: 0.0384567\n",
      "Time:  4.044[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.2_gamma5.0: 4.58132\tvalid_1's Focal_alpha0.2_gamma5.0: 4.80747\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.2_gamma5.0: 0.0109456\tvalid_1's Focal_alpha0.2_gamma5.0: 0.0322228\n",
      "Time:  4.387[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma5.0: 4.38235\tvalid_1's Focal_alpha0.2_gamma5.0: 4.45698\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.2_gamma5.0: 0.0110471\tvalid_1's Focal_alpha0.2_gamma5.0: 0.0703737\n",
      "Time:  4.235[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.3_gamma1.0: 1.5034\tvalid_1's Focal_alpha0.3_gamma1.0: 2.08757\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[48]\ttraining's Focal_alpha0.3_gamma1.0: 0.0937695\tvalid_1's Focal_alpha0.3_gamma1.0: 0.539701\n",
      "Time:  3.636[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma1.0: 1.47515\tvalid_1's Focal_alpha0.3_gamma1.0: 1.92297\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma1.0: 0.107872\tvalid_1's Focal_alpha0.3_gamma1.0: 0.133309\n",
      "Time:  3.699[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma1.0: 0.754516\tvalid_1's Focal_alpha0.3_gamma1.0: 1.53498\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[38]\ttraining's Focal_alpha0.3_gamma1.0: 0.0931828\tvalid_1's Focal_alpha0.3_gamma1.0: 0.496455\n",
      "Time:  3.662[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma1.0: 1.14939\tvalid_1's Focal_alpha0.3_gamma1.0: 1.21533\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[45]\ttraining's Focal_alpha0.3_gamma1.0: 0.0842317\tvalid_1's Focal_alpha0.3_gamma1.0: 0.459348\n",
      "Time:  3.743[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma1.0: 1.45543\tvalid_1's Focal_alpha0.3_gamma1.0: 2.04991\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[41]\ttraining's Focal_alpha0.3_gamma1.0: 0.0852642\tvalid_1's Focal_alpha0.3_gamma1.0: 0.519604\n",
      "Time:  4.398[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.3_gamma2.0: 4.24189\tvalid_1's Focal_alpha0.3_gamma2.0: 4.08815\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma2.0: 0.0619427\tvalid_1's Focal_alpha0.3_gamma2.0: 0.125902\n",
      "Time:  3.859[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma2.0: 3.34134\tvalid_1's Focal_alpha0.3_gamma2.0: 3.19231\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma2.0: 0.0608232\tvalid_1's Focal_alpha0.3_gamma2.0: 0.0838655\n",
      "Time:  4.704[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma2.0: 3.34502\tvalid_1's Focal_alpha0.3_gamma2.0: 3.70634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma2.0: 0.06132\tvalid_1's Focal_alpha0.3_gamma2.0: 0.107001\n",
      "Time:  3.702[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma2.0: 3.73556\tvalid_1's Focal_alpha0.3_gamma2.0: 3.91415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3]\ttraining's Focal_alpha0.3_gamma2.0: 0.0562321\tvalid_1's Focal_alpha0.3_gamma2.0: 0.109402\n",
      "Time:  3.851[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma2.0: 3.0698\tvalid_1's Focal_alpha0.3_gamma2.0: 3.4527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[14]\ttraining's Focal_alpha0.3_gamma2.0: 0.0554575\tvalid_1's Focal_alpha0.3_gamma2.0: 0.254927\n",
      "Time:  4.842[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.3_gamma3.0: 4.27666\tvalid_1's Focal_alpha0.3_gamma3.0: 4.17979\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma3.0: 0.0377706\tvalid_1's Focal_alpha0.3_gamma3.0: 0.100341\n",
      "Time:  3.812[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma3.0: 5.09276\tvalid_1's Focal_alpha0.3_gamma3.0: 5.32674\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma3.0: 0.0371178\tvalid_1's Focal_alpha0.3_gamma3.0: 0.0591464\n",
      "Time:  4.226[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma3.0: 4.89042\tvalid_1's Focal_alpha0.3_gamma3.0: 5.29501\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.3_gamma3.0: 0.0372534\tvalid_1's Focal_alpha0.3_gamma3.0: 0.0863518\n",
      "Time:  4.305[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma3.0: 3.85893\tvalid_1's Focal_alpha0.3_gamma3.0: 3.92586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.3_gamma3.0: 0.0333056\tvalid_1's Focal_alpha0.3_gamma3.0: 0.0732005\n",
      "Time:  4.113[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma3.0: 5.47602\tvalid_1's Focal_alpha0.3_gamma3.0: 5.65196\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.3_gamma3.0: 0.0329387\tvalid_1's Focal_alpha0.3_gamma3.0: 0.135586\n",
      "Time:  3.850[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.3_gamma4.0: 5.62385\tvalid_1's Focal_alpha0.3_gamma4.0: 6.26463\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma4.0: 0.0250134\tvalid_1's Focal_alpha0.3_gamma4.0: 0.0868487\n",
      "Time:  3.748[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma4.0: 5.54005\tvalid_1's Focal_alpha0.3_gamma4.0: 5.30189\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma4.0: 0.024548\tvalid_1's Focal_alpha0.3_gamma4.0: 0.0460582\n",
      "Time:  3.733[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma4.0: 5.10866\tvalid_1's Focal_alpha0.3_gamma4.0: 5.30581\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma4.0: 0.0250671\tvalid_1's Focal_alpha0.3_gamma4.0: 0.0677191\n",
      "Time:  4.556[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma4.0: 5.85156\tvalid_1's Focal_alpha0.3_gamma4.0: 6.23374\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.3_gamma4.0: 0.0209006\tvalid_1's Focal_alpha0.3_gamma4.0: 0.0581721\n",
      "Time:  3.317[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.3_gamma4.0: 8.13573\tvalid_1's Focal_alpha0.3_gamma4.0: 7.43524\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.3_gamma4.0: 0.0208166\tvalid_1's Focal_alpha0.3_gamma4.0: 0.118556\n",
      "Time:  3.562[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.3_gamma5.0: 5.02377\tvalid_1's Focal_alpha0.3_gamma5.0: 4.8762\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma5.0: 0.017986\tvalid_1's Focal_alpha0.3_gamma5.0: 0.0793545\n",
      "Time:  3.620[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.3_gamma5.0: 6.01235\tvalid_1's Focal_alpha0.3_gamma5.0: 6.01337\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma5.0: 0.0175601\tvalid_1's Focal_alpha0.3_gamma5.0: 0.0375424\n",
      "Time:  3.476[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.3_gamma5.0: 5.29146\tvalid_1's Focal_alpha0.3_gamma5.0: 5.963\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.3_gamma5.0: 0.0180991\tvalid_1's Focal_alpha0.3_gamma5.0: 0.0599174\n",
      "Time:  5.102[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.3_gamma5.0: 4.12061\tvalid_1's Focal_alpha0.3_gamma5.0: 4.22093\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.3_gamma5.0: 0.0151666\tvalid_1's Focal_alpha0.3_gamma5.0: 0.0494576\n",
      "Time:  3.901[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.3_gamma5.0: 5.15296\tvalid_1's Focal_alpha0.3_gamma5.0: 5.32173\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\ttraining's Focal_alpha0.3_gamma5.0: 0.0146165\tvalid_1's Focal_alpha0.3_gamma5.0: 0.109467\n",
      "Time:  3.128[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.4_gamma1.0: 3.18135\tvalid_1's Focal_alpha0.4_gamma1.0: 3.53412\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma1.0: 0.128596\tvalid_1's Focal_alpha0.4_gamma1.0: 0.202962\n",
      "Time:  3.385[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma1.0: 3.34107\tvalid_1's Focal_alpha0.4_gamma1.0: 3.84994\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma1.0: 0.126285\tvalid_1's Focal_alpha0.4_gamma1.0: 0.155908\n",
      "Time:  3.903[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma1.0: 3.28148\tvalid_1's Focal_alpha0.4_gamma1.0: 3.52044\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma1.0: 0.126768\tvalid_1's Focal_alpha0.4_gamma1.0: 0.185103\n",
      "Time:  3.393[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma1.0: 3.21261\tvalid_1's Focal_alpha0.4_gamma1.0: 3.83767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma1.0: 0.126375\tvalid_1's Focal_alpha0.4_gamma1.0: 0.177595\n",
      "Time:  3.382[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma1.0: 3.30956\tvalid_1's Focal_alpha0.4_gamma1.0: 3.21377\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma1.0: 0.128956\tvalid_1's Focal_alpha0.4_gamma1.0: 0.260258\n",
      "Time:  4.245[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.4_gamma2.0: 4.93395\tvalid_1's Focal_alpha0.4_gamma2.0: 5.20627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma2.0: 0.0767334\tvalid_1's Focal_alpha0.4_gamma2.0: 0.150032\n",
      "Time:  3.648[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma2.0: 5.02687\tvalid_1's Focal_alpha0.4_gamma2.0: 5.46475\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma2.0: 0.0760676\tvalid_1's Focal_alpha0.4_gamma2.0: 0.104461\n",
      "Time:  3.707[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma2.0: 4.03453\tvalid_1's Focal_alpha0.4_gamma2.0: 4.2518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma2.0: 0.076245\tvalid_1's Focal_alpha0.4_gamma2.0: 0.131761\n",
      "Time:  4.702[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma2.0: 5.62799\tvalid_1's Focal_alpha0.4_gamma2.0: 4.99691\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma2.0: 0.0761234\tvalid_1's Focal_alpha0.4_gamma2.0: 0.122237\n",
      "Time:  3.756[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma2.0: 4.83742\tvalid_1's Focal_alpha0.4_gamma2.0: 4.92358\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma2.0: 0.077228\tvalid_1's Focal_alpha0.4_gamma2.0: 0.20128\n",
      "Time:  8.502[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.4_gamma3.0: 4.73473\tvalid_1's Focal_alpha0.4_gamma3.0: 4.79919\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma3.0: 0.0500962\tvalid_1's Focal_alpha0.4_gamma3.0: 0.122461\n",
      "Time:  6.430[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma3.0: 5.69276\tvalid_1's Focal_alpha0.4_gamma3.0: 6.07134\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma3.0: 0.0502124\tvalid_1's Focal_alpha0.4_gamma3.0: 0.0783925\n",
      "Time:  11.521[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma3.0: 4.79148\tvalid_1's Focal_alpha0.4_gamma3.0: 5.05116\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma3.0: 0.0504216\tvalid_1's Focal_alpha0.4_gamma3.0: 0.105204\n",
      "Time:  5.050[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma3.0: 6.37454\tvalid_1's Focal_alpha0.4_gamma3.0: 6.30925\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma3.0: 0.0502812\tvalid_1's Focal_alpha0.4_gamma3.0: 0.09416\n",
      "Time:  4.019[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma3.0: 5.54835\tvalid_1's Focal_alpha0.4_gamma3.0: 5.77381\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma3.0: 0.0507201\tvalid_1's Focal_alpha0.4_gamma3.0: 0.173867\n",
      "Time:  9.311[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.4_gamma4.0: 6.17325\tvalid_1's Focal_alpha0.4_gamma4.0: 6.88639\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma4.0: 0.035487\tvalid_1's Focal_alpha0.4_gamma4.0: 0.10742\n",
      "Time:  4.460[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.4_gamma4.0: 5.97054\tvalid_1's Focal_alpha0.4_gamma4.0: 6.08373\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma4.0: 0.035882\tvalid_1's Focal_alpha0.4_gamma4.0: 0.0641931\n",
      "Time:  12.005[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma4.0: 6.46506\tvalid_1's Focal_alpha0.4_gamma4.0: 6.41921\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma4.0: 0.0361393\tvalid_1's Focal_alpha0.4_gamma4.0: 0.0899717\n",
      "Time:  9.459[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma4.0: 8.3536\tvalid_1's Focal_alpha0.4_gamma4.0: 8.041\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma4.0: 0.0360091\tvalid_1's Focal_alpha0.4_gamma4.0: 0.0786497\n",
      "Time:  7.419[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.4_gamma4.0: 5.73176\tvalid_1's Focal_alpha0.4_gamma4.0: 5.94099\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma4.0: 0.0360025\tvalid_1's Focal_alpha0.4_gamma4.0: 0.156298\n",
      "Time:  3.827[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.4_gamma5.0: 5.24847\tvalid_1's Focal_alpha0.4_gamma5.0: 5.32135\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma5.0: 0.0269759\tvalid_1's Focal_alpha0.4_gamma5.0: 0.0986558\n",
      "Time:  4.089[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.4_gamma5.0: 5.57469\tvalid_1's Focal_alpha0.4_gamma5.0: 6.01516\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma5.0: 0.0273511\tvalid_1's Focal_alpha0.4_gamma5.0: 0.053648\n",
      "Time:  5.967[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.4_gamma5.0: 6.11469\tvalid_1's Focal_alpha0.4_gamma5.0: 6.36425\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma5.0: 0.0277264\tvalid_1's Focal_alpha0.4_gamma5.0: 0.0808215\n",
      "Time:  3.988[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.4_gamma5.0: 5.31305\tvalid_1's Focal_alpha0.4_gamma5.0: 4.80883\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma5.0: 0.0275227\tvalid_1's Focal_alpha0.4_gamma5.0: 0.0694788\n",
      "Time:  5.218[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.4_gamma5.0: 7.08711\tvalid_1's Focal_alpha0.4_gamma5.0: 7.26204\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.4_gamma5.0: 0.0273333\tvalid_1's Focal_alpha0.4_gamma5.0: 0.14576\n",
      "Time:  6.977[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.5_gamma1.0: 6.93681\tvalid_1's Focal_alpha0.5_gamma1.0: 7.30523\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma1.0: 0.147104\tvalid_1's Focal_alpha0.5_gamma1.0: 0.225113\n",
      "Time:  9.056[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma1.0: 4.36888\tvalid_1's Focal_alpha0.5_gamma1.0: 4.21027\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma1.0: 0.144822\tvalid_1's Focal_alpha0.5_gamma1.0: 0.177398\n",
      "Time:  7.088[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma1.0: 4.49165\tvalid_1's Focal_alpha0.5_gamma1.0: 5.67261\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma1.0: 0.145285\tvalid_1's Focal_alpha0.5_gamma1.0: 0.211738\n",
      "Time:  6.817[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma1.0: 4.04836\tvalid_1's Focal_alpha0.5_gamma1.0: 4.17672\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma1.0: 0.144551\tvalid_1's Focal_alpha0.5_gamma1.0: 0.20502\n",
      "Time:  7.527[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma1.0: 6.04997\tvalid_1's Focal_alpha0.5_gamma1.0: 5.85566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma1.0: 0.147632\tvalid_1's Focal_alpha0.5_gamma1.0: 0.297009\n",
      "Time:  5.768[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.5_gamma2.0: 6.32682\tvalid_1's Focal_alpha0.5_gamma2.0: 7.06165\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma2.0: 0.0925357\tvalid_1's Focal_alpha0.5_gamma2.0: 0.17018\n",
      "Time:  8.337[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma2.0: 5.40463\tvalid_1's Focal_alpha0.5_gamma2.0: 5.35252\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma2.0: 0.0923828\tvalid_1's Focal_alpha0.5_gamma2.0: 0.123311\n",
      "Time:  8.209[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma2.0: 4.89094\tvalid_1's Focal_alpha0.5_gamma2.0: 5.55531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma2.0: 0.0925966\tvalid_1's Focal_alpha0.5_gamma2.0: 0.156572\n",
      "Time:  5.530[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma2.0: 6.98682\tvalid_1's Focal_alpha0.5_gamma2.0: 7.23976\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma2.0: 0.0925163\tvalid_1's Focal_alpha0.5_gamma2.0: 0.149757\n",
      "Time:  7.580[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma2.0: 5.93465\tvalid_1's Focal_alpha0.5_gamma2.0: 6.24491\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma2.0: 0.0934371\tvalid_1's Focal_alpha0.5_gamma2.0: 0.234603\n",
      "Time:  7.075[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.5_gamma3.0: 5.61046\tvalid_1's Focal_alpha0.5_gamma3.0: 5.36997\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma3.0: 0.0641548\tvalid_1's Focal_alpha0.5_gamma3.0: 0.142164\n",
      "Time:  6.965[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma3.0: 7.94582\tvalid_1's Focal_alpha0.5_gamma3.0: 8.68213\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma3.0: 0.0649418\tvalid_1's Focal_alpha0.5_gamma3.0: 0.0951993\n",
      "Time:  6.936[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma3.0: 4.6777\tvalid_1's Focal_alpha0.5_gamma3.0: 4.88268\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma3.0: 0.0650982\tvalid_1's Focal_alpha0.5_gamma3.0: 0.127476\n",
      "Time:  5.093[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma3.0: 4.33636\tvalid_1's Focal_alpha0.5_gamma3.0: 4.6191\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma3.0: 0.0650722\tvalid_1's Focal_alpha0.5_gamma3.0: 0.11929\n",
      "Time:  4.741[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma3.0: 6.88139\tvalid_1's Focal_alpha0.5_gamma3.0: 7.43042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma3.0: 0.0650128\tvalid_1's Focal_alpha0.5_gamma3.0: 0.202916\n",
      "Time:  4.419[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma4.0: 7.67188\tvalid_1's Focal_alpha0.5_gamma4.0: 7.49192\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma4.0: 0.047983\tvalid_1's Focal_alpha0.5_gamma4.0: 0.125759\n",
      "Time:  6.338[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma4.0: 6.10101\tvalid_1's Focal_alpha0.5_gamma4.0: 5.69938\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma4.0: 0.0491136\tvalid_1's Focal_alpha0.5_gamma4.0: 0.0790849\n",
      "Time:  8.501[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma4.0: 6.09503\tvalid_1's Focal_alpha0.5_gamma4.0: 6.15069\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma4.0: 0.0493633\tvalid_1's Focal_alpha0.5_gamma4.0: 0.110844\n",
      "Time:  6.735[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.5_gamma4.0: 5.36148\tvalid_1's Focal_alpha0.5_gamma4.0: 5.74334\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma4.0: 0.0492536\tvalid_1's Focal_alpha0.5_gamma4.0: 0.101842\n",
      "Time:  12.424[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma4.0: 6.15649\tvalid_1's Focal_alpha0.5_gamma4.0: 6.18032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma4.0: 0.0487477\tvalid_1's Focal_alpha0.5_gamma4.0: 0.18508\n",
      "Time:  8.865[s]\n",
      "================================================================================\n",
      "FINISH!\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma5.0: 5.53298\tvalid_1's Focal_alpha0.5_gamma5.0: 5.64293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma5.0: 0.0381087\tvalid_1's Focal_alpha0.5_gamma5.0: 0.115804\n",
      "Time:  7.493[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma5.0: 9.45762\tvalid_1's Focal_alpha0.5_gamma5.0: 9.07233\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma5.0: 0.0392416\tvalid_1's Focal_alpha0.5_gamma5.0: 0.0670975\n",
      "Time:  7.050[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma5.0: 5.29384\tvalid_1's Focal_alpha0.5_gamma5.0: 5.81911\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma5.0: 0.0396349\tvalid_1's Focal_alpha0.5_gamma5.0: 0.100523\n",
      "Time:  4.942[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma5.0: 5.67813\tvalid_1's Focal_alpha0.5_gamma5.0: 5.89549\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma5.0: 0.039395\tvalid_1's Focal_alpha0.5_gamma5.0: 0.0910074\n",
      "Time:  3.297[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's Focal_alpha0.5_gamma5.0: 6.8509\tvalid_1's Focal_alpha0.5_gamma5.0: 7.87702\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's Focal_alpha0.5_gamma5.0: 0.0387732\tvalid_1's Focal_alpha0.5_gamma5.0: 0.174751\n",
      "Time:  3.455[s]\n",
      "================================================================================\n",
      "FINISH!\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'custom',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed': cfg.Params.seed,\n",
    "    'learning_rate': cfg.Params.learning_rate,\n",
    "}\n",
    "\n",
    "alpha_li = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "gamma_li = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "\n",
    "threshold = 0.5\n",
    "results_df = pl.DataFrame([\n",
    "        pl.Series(\"alpha\", [], dtype=pl.Float64),\n",
    "        pl.Series(\"gamma\", [], dtype=pl.Float64),\n",
    "        pl.Series(\"score\", [], dtype=pl.Float64)\n",
    "])\n",
    "for alpha in alpha_li:\n",
    "    for gamma in gamma_li:\n",
    "        oof, models = training.fit_lgbm_fl(train, lgb_params=lgb_params, alpha=alpha, gamma=gamma)\n",
    "        oof_truth = train[cfg.Cols.target].to_numpy()\n",
    "        oof_hat = predict.predict_class(oof, threshold=threshold)\n",
    "        cv_score = metrics.macro_f1_score(oof_truth, oof_hat)\n",
    "        results_df = results_df.vstack(pl.DataFrame({\"alpha\": [alpha], \"gamma\": [gamma], \"score\": [cv_score]}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:55:53.682726Z",
     "start_time": "2024-01-27T05:45:20.513411Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "shape: (25, 3)\n┌───────┬───────┬──────────┐\n│ alpha ┆ gamma ┆ score    │\n│ ---   ┆ ---   ┆ ---      │\n│ f64   ┆ f64   ┆ f64      │\n╞═══════╪═══════╪══════════╡\n│ 0.1   ┆ 1.0   ┆ 0.533271 │\n│ 0.1   ┆ 2.0   ┆ 0.511916 │\n│ 0.1   ┆ 3.0   ┆ 0.52295  │\n│ 0.1   ┆ 4.0   ┆ 0.55393  │\n│ …     ┆ …     ┆ …        │\n│ 0.5   ┆ 2.0   ┆ 0.54792  │\n│ 0.5   ┆ 3.0   ┆ 0.54792  │\n│ 0.5   ┆ 4.0   ┆ 0.547941 │\n│ 0.5   ┆ 5.0   ┆ 0.54792  │\n└───────┴───────┴──────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (25, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>alpha</th><th>gamma</th><th>score</th></tr><tr><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.1</td><td>1.0</td><td>0.533271</td></tr><tr><td>0.1</td><td>2.0</td><td>0.511916</td></tr><tr><td>0.1</td><td>3.0</td><td>0.52295</td></tr><tr><td>0.1</td><td>4.0</td><td>0.55393</td></tr><tr><td>0.1</td><td>5.0</td><td>0.553913</td></tr><tr><td>0.2</td><td>1.0</td><td>0.587359</td></tr><tr><td>0.2</td><td>2.0</td><td>0.614287</td></tr><tr><td>0.2</td><td>3.0</td><td>0.613158</td></tr><tr><td>0.2</td><td>4.0</td><td>0.606373</td></tr><tr><td>0.2</td><td>5.0</td><td>0.562765</td></tr><tr><td>0.3</td><td>1.0</td><td>0.61115</td></tr><tr><td>0.3</td><td>2.0</td><td>0.606071</td></tr><tr><td>0.3</td><td>3.0</td><td>0.586869</td></tr><tr><td>0.3</td><td>4.0</td><td>0.599076</td></tr><tr><td>0.3</td><td>5.0</td><td>0.597265</td></tr><tr><td>0.4</td><td>1.0</td><td>0.54792</td></tr><tr><td>0.4</td><td>2.0</td><td>0.54792</td></tr><tr><td>0.4</td><td>3.0</td><td>0.54792</td></tr><tr><td>0.4</td><td>4.0</td><td>0.547941</td></tr><tr><td>0.4</td><td>5.0</td><td>0.54792</td></tr><tr><td>0.5</td><td>1.0</td><td>0.54792</td></tr><tr><td>0.5</td><td>2.0</td><td>0.54792</td></tr><tr><td>0.5</td><td>3.0</td><td>0.54792</td></tr><tr><td>0.5</td><td>4.0</td><td>0.547941</td></tr><tr><td>0.5</td><td>5.0</td><td>0.54792</td></tr></tbody></table></div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:58:02.511280Z",
     "start_time": "2024-01-27T05:58:02.046622Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "alpha = 0.2\n",
    "gamma = 2.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "START fold 1\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/bokbokbok/utils/functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  yhat = 1. / (1. + np.exp(-yhat))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 1.60143\tvalid_1's Focal_alpha0.2_gamma2.0: 1.73868\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6]\ttraining's Focal_alpha0.2_gamma2.0: 0.0448094\tvalid_1's Focal_alpha0.2_gamma2.0: 0.139674\n",
      "Time:  6.847[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taichi/anaconda3/envs/kaggle/lib/python3.9/site-packages/lightgbm/basic.py:859: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5184\n",
      "[LightGBM] [Info] Number of data points in the train set: 33845, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 1.83143\tvalid_1's Focal_alpha0.2_gamma2.0: 1.7892\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[22]\ttraining's Focal_alpha0.2_gamma2.0: 0.0457543\tvalid_1's Focal_alpha0.2_gamma2.0: 0.185867\n",
      "Time:  6.108[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 3\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5178\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 1.10057\tvalid_1's Focal_alpha0.2_gamma2.0: 1.30991\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[22]\ttraining's Focal_alpha0.2_gamma2.0: 0.0443517\tvalid_1's Focal_alpha0.2_gamma2.0: 0.241077\n",
      "Time:  6.792[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 4\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5174\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 3.76207\tvalid_1's Focal_alpha0.2_gamma2.0: 3.81505\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4]\ttraining's Focal_alpha0.2_gamma2.0: 0.0445657\tvalid_1's Focal_alpha0.2_gamma2.0: 0.0983678\n",
      "Time:  5.340[s]\n",
      "--------------------------------------------------------------------------------\n",
      "START fold 5\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5177\n",
      "[LightGBM] [Info] Number of data points in the train set: 33846, number of used features: 35\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Focal_alpha0.2_gamma2.0: 2.56407\tvalid_1's Focal_alpha0.2_gamma2.0: 2.63903\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5]\ttraining's Focal_alpha0.2_gamma2.0: 0.0447159\tvalid_1's Focal_alpha0.2_gamma2.0: 0.141217\n",
      "Time:  6.599[s]\n",
      "================================================================================\n",
      "FINISH!\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.2\n",
    "gamma = 2.0\n",
    "oof, models = training.fit_lgbm_fl(train, lgb_params=lgb_params, alpha=alpha, gamma=gamma)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:59:51.969985Z",
     "start_time": "2024-01-27T05:59:19.641355Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:01:58.257101Z",
     "start_time": "2024-01-27T06:01:58.219310Z"
    }
   },
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_prob = predict.predict_probability_sigmoid(models, test)\n",
    "pred_class = predict.predict_class(pred_prob, threshold=threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:01:59.127947Z",
     "start_time": "2024-01-27T06:01:58.887807Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CV score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614287119545442\n"
     ]
    }
   ],
   "source": [
    "oof_truth = train[cfg.Cols.target].to_numpy()\n",
    "oof_hat = predict.predict_class(oof, threshold=threshold)\n",
    "cv_score = metrics.macro_f1_score(oof_truth, oof_hat)\n",
    "print(cv_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:02:01.608310Z",
     "start_time": "2024-01-27T06:02:01.551343Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### oofとtestの予測値分布を比較してバグを確認"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(oof)\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:00:15.024009Z",
     "start_time": "2024-01-27T06:00:13.977013Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(pred_prob)\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:00:17.774356Z",
     "start_time": "2024-01-27T06:00:16.379465Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 予測値の1の割合を確認"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8786990640068072\n"
     ]
    }
   ],
   "source": [
    "print(pred_class.sum() / len(pred_class))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:02:06.762520Z",
     "start_time": "2024-01-27T06:02:06.712710Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "### oofにおける混同行列を確認"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative Rate (0の正解率): 0.51\n",
      "True Positive Rate (1の正解率): 0.83\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.show_confusion_matrix(oof_truth, oof_hat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:02:35.372599Z",
     "start_time": "2024-01-27T06:02:34.577216Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T06:02:52.013044Z",
     "start_time": "2024-01-27T06:02:51.933209Z"
    }
   },
   "outputs": [],
   "source": [
    "submit = submit.with_columns([pl.Series(cfg.Cols.sub_pred, pred_class)])\n",
    "utils.make_submission(submit, exp, cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T05:34:32.592278Z",
     "start_time": "2024-01-27T05:34:32.580483Z"
    }
   },
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
